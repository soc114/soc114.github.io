---
title: "Preparing Data Exercise"
format: pdf
---

This exercise examines how income inequality has changed over time in the U.S. We will measure inequality by the 10th, 50th, and 90th percentiles of wage and salary income from 1962 to 2022.^[Thanks to past TA Abby Sachar for designing the base of this exercise.] The goal is to produce a graph like this one.

```{r}
library(tidyverse)
library(haven)
```

If you don't have `haven`, you will need to install with `install.packages("haven")` in your console.

The course website talks about where you can access data. For now, we will use simulated data.

```{r}
cps_data <- read_dta("https://soc114.github.io/data/simulated_cps_data.dta")
```

## Explore the data

Type `cps_data` in the console. Some columns such as [`educ`](https://cps.ipums.org/cps-action/variables/educ#codes_section) have a numeric code and a label. The code is how IPUMS has stored the data. The label is what the code means. You can always find more documentation explaining the labels on the [IPUMS-CPS website](https://cps.ipums.org/cps-action/variables/educ#codes_section).

<!-- {{< video https://www.youtube.com/embed/f9IeokvW8HM >}} -->

## filter() to cases of interest

> In this step, you will use [`filter()`](https://dplyr.tidyverse.org/reference/filter.html) to convert your `cps_data` object to a new object called `filtered`.

The [`filter()`](https://dplyr.tidyverse.org/reference/filter.html) function keeps only rows in our dataset that correspond to those we want to study. The [examples](https://dplyr.tidyverse.org/reference/filter.html#ref-examples) on the documentation page are especially helpful. The [R4DS section](https://r4ds.hadley.nz/data-transform#filter) is also helpful.

Here are two ways to use [`filter()`](https://dplyr.tidyverse.org/reference/filter.html) to restrict to people working 50+ weeks per year. One way is to call the `filter()` function and hand it two arguments

- `.data = cps_data` is the dataset
- `year == 1962` is a logical condition coded `TRUE` for observations in 1962

```{r, eval = F}
filter(.data = cps_data, year == 1962)
```

The result of this call is a [`tibble`](https://tibble.tidyverse.org/) with only the observations from 1962. Another way to do the same operation is with the pipe operator `|>`

```{r, eval = F}
cps_data |>
  filter(year == 1962)
```

This approach begins with the data set `cps_data`. The pipe operator `|>` hands this data set on as the first argument to the [`filter()`](https://dplyr.tidyverse.org/reference/filter.html) function in the next line. As before, the second argument is the logical condition `year == 1962`.

The piping approach is often preferable because it reads like a sentence: begin with data, then filter to cases with a given condition. The pipe is also useful 

The pipe operator `|>` takes what is on the first line and hands it on as the first argument to the function in the next line. This reads in a sentence: begin with the `cps_data` tibble and then [`filter()`](https://dplyr.tidyverse.org/reference/filter.html) to cases with `year == 1962`. The pipe can also string together many operations, with comments allowed between them:

```{r, eval = F}
cps_data |>
  # Restrict to 1962
  filter(year == 1962) |>
  # Restrict to ages 40-44
  filter(age >= 40 & age <= 44)
```

**Your turn.** Begin with the `cps_data` dataset. Filter to

- people working 50+ weeks per year (check documentation for [`wkswork2`](https://cps.ipums.org/cps-action/variables/WKSWORK2#codes_section)) 
- valid report of [`incwage`](https://cps.ipums.org/cps-action/variables/INCWAGE) greater than 0 and less than 99999998

```{r}
#| code-fold: true
#| code-summary: "Show the code answer"
filtered <- cps_data |>
  # Subset to cases working full year
  filter(wkswork2 == 6) |>
  # Subset to cases with valid income
  filter(incwage > 0 & incwage < 99999998)
```

::: {.callout-note}
Filtering can be a dangerous business! For example, above we dropped people with missing values of income. But what if the lowest-income people refuse to answer the income question? We often have no choice but to filter to those with valid responses, but you should always read the documentation to be sure you understand who you are dropping and why.
:::

{{< video https://www.youtube.com/embed/OE2gE_3DLf8 >}}


## group_by() and summarize() for subpopulation summaries

> In this step, you will use `group_by()` and `summarize()` to convert your `mutated` object to a new object called `summarized`.

Each row in our dataset is a person. We want a dataset where each row is a year. To get there, we will group our data by year and then summarize each group by a set of summary statistics.

### Introducing summarize() with the sample mean

To see how `summarize()` works, let's first summarize the sample mean income within each year. The input has one row per person. The result has one row per group. For each year, it records the sample mean income.

```{r}
filtered |>
  group_by(year) |>
  summarize(mean_income = mean(incwage))
```

{{< video https://www.youtube.com/embed/loOJDf1aF-w >}}

### Using summarize() with weighted quantiles

Instead of the mean, we plan to use three other summary statistics: the 10th, 50th, and 90th percentiles of income. We also want to incorporate the sampling weights provided with the Current Population Survey, in order to summarize the population instead of the sample.

We will use the `wtd.quantile` function to create weighted quantiles. This function is available in the `Hmisc` package. If you don't have that package, install it with `install.packages("Hmisc")`. Using the `Hmisc` package is tricky, because it has some functions with the same name as functions that we use in the `tidyverse`. Instead of loading the whole package, we will only load the functions we are using at the time we use them. Whenever we want to calculate a weighted quantile, we will call it with the code `packagename::functionname()` which in this case is `Hmisc::wtd.quantile()`.

The `wtd.quantile` function will take three arguments:

* `x` is the variable to be summarized
* `weights` is the variable containing sampling weights
* `probs` is the probability cutoffs for the quantiles. For the 10th, 50th, and 90th percentiles we want 0.1, 0.5, and 0.9.

The code below produces weighted quantile summaries.

```{r}
summarized <- filtered |>
  group_by(year) |>
  summarize(
    p10 = Hmisc::wtd.quantile(x = incwage, weights = asecwt, probs = 0.1),
    p50 = Hmisc::wtd.quantile(x = incwage, weights = asecwt, probs = 0.5),
    p90 = Hmisc::wtd.quantile(x = incwage, weights = asecwt, probs = 0.9),
    .groups = "drop"
  )
```

{{< video https://www.youtube.com/embed/IOMbo_3ynKU >}}

## pivot_longer() to reshape data

> In this step, you will use `pivot_longer()` to convert your `summarized` object to a new object called `pivoted`. We first explain why, then explain the task.

We ultimately want to make a `ggplot()` where income values are placed on the y-axis. We want to plot the 10th, 50th, and 90th percentiles along this axis, distinguished by color. We need them all in one colun! But currently, they are in three columns.

Here is the task. How our data look:

```{r, echo = F}
summarized |>
  print(n = 2)
```
    
Here we want our data to look:

```{r, echo = F}
summarized |>
  pivot_longer(cols = c("p10","p50","p90"),
               names_to = "quantity",
               values_to = "income") |>
  print(n = 6)
```

This way, we can use `year` for the x-axis, `quantity` for color, and `value` for the y-axis.

Use [`pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html) to change the first data frame to the second.

- Use the `cols` argument to tell it which columns will disappear
- Use the `names_to` argument to tell R that the names of those
  variables will be moved to a column called `quantity`
- Use the `values_to` argument to tell R that the values of those
  variables will be moved to a column called `income`
  
If you get stuck, see how we did it at the [end of this page](#all-together).

```{r}
#| code-fold: true
#| code-summary: "Show the code answer"
pivoted <- summarized %>%
  pivot_longer(
    cols = c("p10","p50","p90"),
    names_to = "quantity",
    values_to = "income"
  )
```

{{< video https://www.youtube.com/embed/DRuPHsX6GlM >}}

## left_join() an inflation adjustment

> In this step, you will use [`left_join()`](https://r4ds.hadley.nz/joins#sec-mutating-joins) to merge in an inflation adjustment

A dollar in 1962 bought a lot more than a dollar in 2022. We will adjust for inflation using the [Consumer Price Index](https://www.bls.gov/cpi/), which tracks the cost of a standard basket of market goods. We already took this index to create a file `inflation.csv`,

```{r}
inflation <- read_csv("https://soc114.github.io/data/inflation.csv")
```

The `inflation_factor` tells us that \$1 in 1962 could buy about as much as \$10.10 in 2023. To take a 1962 income and report it in 2023 dollars, we should multiple it by 10.1. We need to join our data
```{r, echo = F}
pivoted |>
  print(n = 3)
```
together with `inflation.csv` by the linking variable `year`. Use [`left_join()`](https://r4ds.hadley.nz/joins#sec-mutating-joins) to merge `inflation_factor` onto the dataset `pivoted`. Below is a hypothetical example for the structure.

```{r, eval = F}
# Hypothetical example
joined <- data_A |>
  left_join(
    data_B,
    by = join_by(key_variable_in_A_and_B)
  )
```

```{r}
#| code-fold: true
#| code-summary: "Show the code answer"
joined <- pivoted |>
  left_join(
    inflation,
    by = join_by(year)
  )
```

{{< video https://www.youtube.com/embed/EptsO1HLBs4 >}}

## mutate() to adjust for inflation

> In this step, you will use [`mutate()`](https://r4ds.hadley.nz/data-transform#sec-mutate) to multiple `income` by the `inflation_factor`

The [`mutate()`](https://r4ds.hadley.nz/data-transform#sec-mutate) function modifies columns. It can overwrite existing columns or create new columns at the right of the data set. The new variable is some transformation of the old variables.

```{r, eval = F}
# Hypothetical example
old_data |>
  mutate(new_variable = old_variable_1 + old_variable_2)
```

Use [`mutate()`](https://r4ds.hadley.nz/data-transform#sec-mutate) to modify `income` so that it takes the values `income * inflation_factor`.

```{r}
#| code-fold: true
#| code-summary: "Show the code answer"
mutated <- joined |>
  mutate(income = income * inflation_factor)
```

{{< video https://www.youtube.com/embed/H0vxvCYDuzU >}}

## ggplot() to visualize

Now make a `ggplot()` where

- `year` is on the x-axis
- `income` is on the y-axis
- `quantity` is denoted by color

Discuss. What do you see in this plot?

```{r, include = F}
joined |>
  # Produce a ggplot
  ggplot(aes(x = year, y = income, color = quantity)) +
  geom_line() +
  xlab("Year") +
  scale_y_continuous(name = "Annual Wage and Salary Income\n(2023 dollars)",
                     labels = scales::label_dollar()) +
  scale_color_discrete(name = "Percentile of\nDistribution",
                       labels = function(x) paste0(gsub("p","",x),"th")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## All together

Putting it all together, we have a pipeline that goes from data to the plot.

```{r, fig.height = 3, comment = F, warning = F, message = F}
cps_data |>
  # Subset to cases working full year
  filter(wkswork2 == 6) |>
  # Subset to cases with valid income
  filter(incwage > 0 & incwage < 99999998) |>
  # Produce summaries
  group_by(year) |>
  summarize(
    p10 = Hmisc::wtd.quantile(x = incwage, weights = asecwt, probs = 0.1),
    p50 = Hmisc::wtd.quantile(x = incwage, weights = asecwt, probs = 0.5),
    p90 = Hmisc::wtd.quantile(x = incwage, weights = asecwt, probs = 0.9
    ),
    .groups = "drop"
  ) |>
  pivot_longer(
    cols = c("p10","p50","p90"),
    names_to = "quantity",
    values_to = "income"
  ) |>
  # Join data for inflation adjustment
  left_join(
    read_csv("https://soc114.github.io/data/inflation.csv"),
    by = join_by(year)
  ) |>
  # Apply the inflation adjustment
  mutate(income = income * inflation_factor) |>
  # Produce a ggplot
  ggplot(aes(x = year, y = income, color = quantity)) +
  geom_line() +
  xlab("Year") +
  scale_y_continuous(name = "Annual Wage and Salary Income\n(2023 dollars)",
                     labels = scales::label_dollar()) +
  scale_color_discrete(name = "Percentile of\nDistribution",
                       labels = function(x) paste0(gsub("p","",x),"th")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

{{< video https://www.youtube.com/embed/fgQe7BaZEMQ >}}

## Want to do more?

If you have finished and want to do more, you could

- incorporate the [`educ`](https://cps.ipums.org/cps-action/variables/educ#codes_section) variable in your plot. You might want to group by those who do and do not hold college degrees, perhaps using [`facet_grid()`](https://ggplot2.tidyverse.org/reference/facet_grid.html)
- try [`geom_histogram()`](https://ggplot2.tidyverse.org/reference/geom_histogram.html) for people's incomes in a specific year
- explore [IPUMS-CPS](https://cps.ipums.org/) for other variables and begin your own visualization


