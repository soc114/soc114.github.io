---
title: "Why model?"
format: 
  html:
    fig-height: 3
---

> Covered Feb 11. Here are [slides](../slides/lec11a_whymodel/lec11a_whymodel.pdf). Lecture for today also includes the next page.

<!-- > The reading with this class is [Berk 2020 Ch 1](https://link.springer.com/book/10.1007/978-3-030-40189-4) p. 1--5, stopping at paragraph ending "...is nonlinear." Then p. 14--17 "Model misspecification..." through "...will always be in play." -->

This page will help you

- explain the curse of dimensionality
- recognize the possible futility of nonparametric estimation

It motivates the **model-based estimation** that we will use in the next part of the course.

## A motivating example

Sociologists who study household income inequality often focus on two mechanisms. First, incomes vary across individuals. Second, individuals pool together into households. The tendency of high-income individuals to marry other high-income individuals is thus an important process through which household income inequality arises.^[[Mare 1991](https://doi.org/10.2307/2095670), [Schwartz 2013](https://doi.org/10.1146/annurev-soc-071312-145544)]

This page asks a question about the pooling of people together into households: To what degree does finishing college increase the probability of having a spouse who finished college?

## Data

We use data from the [National Longitudinal Survey of Youth 1997](https://www.bls.gov/nls/nlsy97.htm) (NLSY97). The NLSY97 is a probability sample of U.S. non-institutional civilian youths age 12--16 on Dec 31 1996 ($n$ = 8,984). Sampled individuals were surveyed annually 1997--2011, then biennially.

If you would like to work with the data, you should first prepare your computer with some files from us:

* set your working directory where you will be working
* download two supporting files from us
     1. [`nlsy97.NLSY97`](https://drive.google.com/file/d/1YcyaC1R5u9_d0-AX4ivqDiU0bRnEsAsJ/view?usp=sharing) is a tagset file containing the variable names
     2. [`prepare_nlsy97.R`](https://drive.google.com/file/d/1fUdlhEsGGC0shREvu4znPPmJjtNi--Ko/view?usp=sharing) is an R script to prepare the data

Now go to the data distributor

1. [Register](https://nlsinfo.org/investigator/pages/register) with the survey
2. [Log in](https://nlsinfo.org/investigator/pages/login) to the NLS Investigator
3. Choose the NLSY97 study
4. Upload the tagset [`nlsy97.NLSY97`](https://drive.google.com/file/d/1YcyaC1R5u9_d0-AX4ivqDiU0bRnEsAsJ/view?usp=sharing) that you downloaded from us
5. In the Investigator, download the data. Type to change the file name from `default` to `nlsy97`
6. Unzip the file. Drag `nlsy97.dat` into the folder you will work in
7. In your R console, run the line of code below
     * this will take about 30 seconds to run
     * you will need these R packages: `tidyverse` and `Amelia`

```{r, warning = F, message = F}
library(tidyverse)
```

```{r, eval = F}
source("prepare_nlsy97.R")
```
In the future, you can now load the data with 
```{r, eval = F}
d <- readRDS("d.RDS")
```
```{r, echo = F}
d <- readRDS("../data_raw/d.RDS")
```

## A DAG with one confounder

To draw a DAG, we first define our treatment and outcome variables

- Treatment $A$: Finished BA by age 25
- Outcome $Y$: Spouse or partner at age 30--40 holds a BA
     * 0 if no spouse or partner, or partner with no BA
     * 1 if spouse or partner holds a BA
     
With these two variables, we ask whether there are any other variables that are common ancestors of these two. One possibility is the sex of the respondent, $L$.

```{tikz, echo = F}
\begin{tikzpicture}[x = 1in, y = .7in]
\node at (-3,0) {};
\node at (3,0) {};
\node (a) at (0,0) {$A$};
\node (y) at (1,0) {$Y$};
\node (l) at (-1,0) {$L$};
\draw[->, thick] (l) -- (a);
\draw[->, thick] (a) -- (y);
\draw[->, thick] (l) to[bend left] (y);
\node[anchor = north, align = center, font = \footnotesize] at (a.south) {College\\Degree\\by Age 25};
\node[anchor = north, align = center, font = \footnotesize] at (y.south) {Spouse\\at Age 35\\Has Degree};
\node[anchor = north, align = center, font = \footnotesize] at (l.south) {Sex};
\end{tikzpicture}
```

If this were the only confounder, our adjustment procedure would be simple:

1) Estimate within subgroups defined by \{sex\}
2) Aggregate over the subgroups

The code below estimates within the subgroups

```{r}
ybar_in_subgroups <- d |>
  # Group by confounders and treatment
  group_by(sex, a) |>
  # Summarize mean outcomes and nber of cases
  summarize(ybar = mean(y),
            n = n(),
            .groups = "drop") |>
  pivot_wider(names_from = a,
              values_from = c("ybar","n")) |>
  print()
```

Then we can aggregate over the subgroups, weighted by size.

```{r}
ybar_in_subgroups |>
  mutate(
    conditional_effect = ybar_college - ybar_no_college,
    n_in_stratum = n_college + n_no_college
  ) |>
  select(sex, conditional_effect, n_in_stratum) |>
  summarize(
    population_average_effect = weighted.mean(
      conditional_effect,
      w = n_in_stratum
    )
  ) |>
  print()
```

The visualization below seeks to build intuitiomn for what we have just done. We split the population into two subgroups (left and right of the solid line). Within each subgroup, we took the mean outcome among those with and without college degrees (above and below dashed line), taking the difference as the effect of a college degree. Then we took the average across the left and right subgroups.

```{r, echo = F}
#| fig-height: 3
viz_data <- d |>
  group_by(sex) |>
  summarize(num = n(), 
            prop_treated = mean(a == "college"),
            .groups = "drop") |>
  mutate(proportion = num / sum(num)) |>
  arrange(sex) |>
  mutate(cdf = cumsum(proportion),
         cdf_min = lag(cdf),
         cdf_min = ifelse(is.na(cdf_min),0,cdf_min),
         cdf_mid = .5 * (cdf_min + cdf),
         treated_mid = (1 - .5 * prop_treated),
         untreated_mid = .5 * (1 - prop_treated))

plot_by_sex <- viz_data |>
  ggplot() +
  geom_rect(aes(xmin = cdf_min, xmax = cdf,
             ymin = 0, ymax = 1),
            fill = NA, color = "black") +
  geom_text(aes(x = cdf_mid, y = -.05,
                label = sex),
            vjust = 1) +
  geom_segment(aes(x = cdf_min, xend = cdf, 
                   y = 1 - prop_treated,
                   yend = 1 - prop_treated),
               linetype = "dashed") +
  geom_text(aes(x = cdf_mid, y = treated_mid),
            label = "College") +
  geom_text(aes(x = cdf_mid, y = untreated_mid),
            label = "No College") +
  ylim(c(-.1,1.1)) +
  theme_void()
plot_by_sex
```

## With two confounders

Sex may not be the only confounder. What if race also shapes access to college and the probability of having a college-educated spouse at age 35?

```{tikz, echo = F}
\begin{tikzpicture}[x = 1in, y = .4in]
\node (a) at (0,0) {$A$};
\node (y) at (1,0) {$Y$};
\node (l1) at (-1,1) {$L_1$};
\node (l2) at (-1,0) {$L_2$};
\draw[->, thick] (l1) -- (a);
\draw[->, thick] (l2) -- (a);
\draw[->, thick] (a) -- (y);
\draw[->, thick] (l1) to[bend left] (y);
\draw[->, thick] (l2) to[bend left] (y);
\node[anchor = north, align = center, font = \footnotesize] at (a.south) {College\\Degree\\by Age 25};
\node[anchor = north, align = center, font = \footnotesize] at (y.south) {Spouse\\at Age 35\\Has Degree};
\node[anchor = east, align = center, font = \footnotesize] at (l1.west) {Sex};
\node[anchor = east, align = center, font = \footnotesize] at (l2.west) {Race};
\end{tikzpicture}
```

Our procedure would be analogous to the above:

1) Estimate effects within subgroups defined by \{sex, race\}
2) Aggregate over subgroups

The only difference is that now there are 6 subgroups (3 race categories $\times$ 2 sex categories). Moving from one to two confounders multiplies the number of subgroups.

```{r, echo = F}
#| fig-height: 4
viz_data <- d |>
  group_by(race, sex) |>
  summarize(num = n(), 
            prop_treated = mean(a == "college"),
            .groups = "drop_last") |>
  mutate(proportion = num / sum(num)) |>
  arrange(sex) |>
  mutate(cdf = cumsum(proportion),
         cdf_min = lag(cdf),
         cdf_min = ifelse(is.na(cdf_min),0,cdf_min),
         cdf_mid = .5 * (cdf_min + cdf),
         treated_mid = (1 - .5 * prop_treated),
         untreated_mid = .5 * (1 - prop_treated))

plot_by_sex_race <- viz_data |>
  ggplot() +
  geom_rect(aes(xmin = cdf_min, xmax = cdf,
             ymin = 0, ymax = 1),
            fill = NA, color = "black") +
  geom_text(aes(x = cdf_mid, y = -.05,
                label = sex),
            vjust = 1) +
  geom_segment(aes(x = cdf_min, xend = cdf, 
                   y = 1 - prop_treated,
                   yend = 1 - prop_treated),
               linetype = "dashed") +
  geom_text(aes(x = cdf_mid, y = treated_mid),
            label = "College") +
  geom_text(aes(x = cdf_mid, y = untreated_mid),
            label = "No College") +
  ylim(c(-.1,1.1)) +
  theme_void() +
  facet_wrap(~race) +
  theme(strip.text = element_text(face = "bold"))
plot_by_sex_race
```

Below are the unadjusted estimates and the estimates adjusted for sex and race.

```{r, echo = F}
#| fig-height: 3
descriptive <- d |>
  group_by(a) |>
  summarize(ybar = mean(y)) |>
  pivot_wider(names_from = a, values_from = ybar) |>
  mutate(difference = college - no_college) |>
  pivot_longer(cols = everything()) |>
  mutate(name = fct_relevel(name,"college","no_college","difference")) |>
  mutate(quantity = "Descriptive\n(Unadjusted)")

causal <- d |>
  # Group by confounders and treatment
  group_by(sex, race, a) |>
  # Estimate within subgroups
  summarize(ybar = mean(y),
            n = n(),
            .groups = "drop") |>
  pivot_wider(names_from = a,
              values_from = c("ybar","n")) |>
  mutate(n = n_no_college + n_college) |>
  summarize(college = weighted.mean(ybar_college, w = n),
            no_college = weighted.mean(ybar_no_college, w = n),
            difference = weighted.mean(ybar_college - ybar_no_college,
                                       w = n)) |>
  pivot_longer(cols = everything()) |>
  mutate(name = fct_relevel(name,"college","no_college","difference")) |>
  mutate(quantity = "Causal\n(Adjusted)")

descriptive |>
  bind_rows(causal) |>
  mutate(quantity = fct_rev(quantity)) |>
  ggplot(aes(x = name, y = value,
             label = format(round(value,2),nsmll = 2))) +
  geom_point() +
  geom_text(nudge_x = .1, hjust = 0) +
  facet_wrap(~quantity) +
  scale_x_discrete(labels = as_labeller(function(x) {
    case_when(x == "college" ~ "(1)\nUnder College",
              x == "no_college" ~ "(2)\nUnder No College",
              x == "difference" ~ "(1) - (2)\nDifference")
  })) +
  xlab("Estimand") +
  ylab("Estimate") +
  ylim(c(0,1)) +
  theme_bw()
```

## With three confounders

Sex and race are not likely to be a sufficient adjustment set. Our DAG should really include at least three confounders:

```{tikz, echo = F}
\begin{tikzpicture}[x = 1in, y = .4in]
\node (a) at (0,0) {$A$};
\node (y) at (1,0) {$Y$};
\node (l1) at (-1,1) {$L_1$};
\node (l2) at (-1,.5) {$L_2$};
\node (l3) at (-1,0) {$L_3$};
\draw[->, thick] (l1) -- (a);
\draw[->, thick] (l2) -- (a);
\draw[->, thick] (l3) -- (a);
\draw[->, thick] (a) -- (y);
\draw[->, thick] (l1) to[bend left] (y);
\draw[->, thick] (l2) to[bend left] (y);
\draw[->, thick] (l3) to[bend left] (y);
\node[anchor = north, align = center, font = \footnotesize] at (a.south) {College\\Degree\\by Age 25};
\node[anchor = north, align = center, font = \footnotesize] at (y.south) {Spouse\\at Age 35\\Has Degree};
\node[anchor = east, align = center, font = \footnotesize] at (l1.west) {Sex};
\node[anchor = east, align = center, font = \footnotesize] at (l2.west) {Race};
\node[anchor = east, align = center, font = \footnotesize] at (l3.west) {Mom Education};
\end{tikzpicture}
```

Proceeding as above, we can make a nonparametric estimate:

1) Estimate effects within subgroups defined by \{race,sex, mom education\}
2) Aggregate over subgroups

The number of subgroups is starting to get quite large!

```{r, echo = F}
#| fig-height: 8
viz_data <- d |>
  group_by(race, mom_educ, sex) |>
  summarize(num = n(), 
            prop_treated = mean(a == "college"),
            .groups = "drop_last") |>
  mutate(proportion = num / sum(num)) |>
  arrange(sex) |>
  mutate(cdf = cumsum(proportion),
         cdf_min = lag(cdf),
         cdf_min = ifelse(is.na(cdf_min),0,cdf_min),
         cdf_mid = .5 * (cdf_min + cdf),
         treated_mid = (1 - .5 * prop_treated),
         untreated_mid = .5 * (1 - prop_treated))

plot_by_sex_race_mom_educ <- viz_data |>
  ggplot() +
  geom_rect(aes(xmin = cdf_min, xmax = cdf,
             ymin = 0, ymax = 1),
            fill = NA, color = "black") +
  geom_text(aes(x = cdf_mid, y = -.05,
                label = sex),
            vjust = 1) +
  geom_segment(aes(x = cdf_min, xend = cdf, 
                   y = 1 - prop_treated,
                   yend = 1 - prop_treated),
               linetype = "dashed") +
  geom_text(aes(x = cdf_mid, y = treated_mid),
            label = "College") +
  geom_text(aes(x = cdf_mid, y = untreated_mid),
            label = "No College") +
  ylim(c(-.1,1.1)) +
  theme_void() +
  facet_grid(mom_educ~race) +
  theme(strip.text = element_text(face = "bold"))
plot_by_sex_race_mom_educ
```

```{r, echo = F}
#| fig-height: 3
causal <- d |>
  # Group by confounders and treatment
  group_by(sex, race, mom_educ, a) |>
  # Estimate within subgroups
  summarize(ybar = mean(y),
            n = n(),
            .groups = "drop") |>
  pivot_wider(names_from = a,
              values_from = c("ybar","n")) |>
  mutate(n = n_no_college + n_college) |>
  summarize(college = weighted.mean(ybar_college, w = n),
            no_college = weighted.mean(ybar_no_college, w = n),
            difference = weighted.mean(ybar_college - ybar_no_college,
                                       w = n)) |>
  pivot_longer(cols = everything()) |>
  mutate(name = fct_relevel(name,"college","no_college","difference")) |>
  mutate(quantity = "Causal\n(Adjusted)")

descriptive |>
  bind_rows(causal) |>
  mutate(quantity = fct_rev(quantity)) |>
  ggplot(aes(x = name, y = value,
             label = format(round(value,2),nsmll = 2))) +
  geom_point() +
  geom_text(nudge_x = .1, hjust = 0) +
  facet_wrap(~quantity) +
  scale_x_discrete(labels = as_labeller(function(x) {
    case_when(x == "college" ~ "(1)\nUnder College",
              x == "no_college" ~ "(2)\nUnder No College",
              x == "difference" ~ "(1) - (2)\nDifference")
  })) +
  xlab("Estimand") +
  ylab("Estimate") +
  ylim(c(0,1)) +
  theme_bw() +
  theme(text = element_text(size = 16))
```

## With four confounders

Now we suppose that dad's education is also a confounder.

```{tikz, echo = F}
\begin{tikzpicture}[x = 1in, y = .4in]
\node (a) at (0,0) {$A$};
\node (y) at (1,0) {$Y$};
\node (l1) at (-1,1) {$L_1$};
\node (l2) at (-1,.66) {$L_2$};
\node (l3) at (-1,.33) {$L_3$};
\node (l4) at (-1,0) {$L_4$};
\draw[->, thick] (l1) -- (a);
\draw[->, thick] (l2) -- (a);
\draw[->, thick] (l3) -- (a);
\draw[->, thick] (l4) -- (a);
\draw[->, thick] (a) -- (y);
\draw[->, thick] (l1) to[bend left] (y);
\draw[->, thick] (l2) to[bend left] (y);
\draw[->, thick] (l3) to[bend left] (y);
\draw[->, thick] (l4) to[bend left] (y);
\node[anchor = north, align = center, font = \footnotesize] at (a.south) {College\\Degree\\by Age 25};
\node[anchor = north, align = center, font = \footnotesize] at (y.south) {Spouse\\at Age 35\\Has Degree};
\node[anchor = east, align = center, font = \footnotesize] at (l1.west) {Sex};
\node[anchor = east, align = center, font = \footnotesize] at (l2.west) {Race};
\node[anchor = east, align = center, font = \footnotesize] at (l3.west) {Mom Education};
\node[anchor = east, align = center, font = \footnotesize] at (l4.west) {Dad Education};
\end{tikzpicture}
```

The procedure still holds:

1) Estimate effects within subgroups defined by \{race,sex, mom education, dad education\}
2) Aggregate over subgroups

but the number of subgroups is now *very* many.

```{r, echo = F}
#| fig-height: 12
viz_data <- d |>
  group_by(race, mom_educ, dad_educ, sex) |>
  summarize(num = n(), 
            prop_treated = mean(a == "college"),
            .groups = "drop_last") |>
  mutate(proportion = num / sum(num)) |>
  arrange(sex) |>
  mutate(cdf = cumsum(proportion),
         cdf_min = lag(cdf),
         cdf_min = ifelse(is.na(cdf_min),0,cdf_min),
         cdf_mid = .5 * (cdf_min + cdf),
         treated_mid = (1 - .5 * prop_treated),
         untreated_mid = .5 * (1 - prop_treated))

plot_by_sex_race_mom_educ_dad_educ <- viz_data |>
  ggplot() +
  geom_rect(aes(xmin = cdf_min, xmax = cdf,
             ymin = 0, ymax = 1),
            fill = NA, color = "black") +
  geom_text(aes(x = cdf_mid, y = -.05,
                label = sex),
            vjust = 1) +
  geom_segment(aes(x = cdf_min, xend = cdf, 
                   y = 1 - prop_treated,
                   yend = 1 - prop_treated),
               linetype = "dashed") +
  geom_text(aes(x = cdf_mid, y = treated_mid),
            label = "College", size = 2) +
  geom_text(aes(x = cdf_mid, y = untreated_mid),
            label = "No College", size = 2) +
  ylim(c(-.1,1.1)) +
  theme_void() +
  facet_grid(mom_educ + dad_educ ~race) +
  theme(strip.text = element_text(face = "bold"))
```

Now we have a problem. Some subgroups (highlighted in red) are unpopulated: there are no sampled units in these subgroups. The problem of unpopulated cells happens because we have many confounders, so that there are a huge number of subgroups. This problem is known as the curse of dimensionality.

```{r, echo = F}
#| fig-height: 12
plot_by_sex_race_mom_educ_dad_educ +
  geom_rect(aes(xmin = cdf_min, xmax = cdf,
                ymin = 0, ymax = 1,
                alpha = prop_treated %in% c(0,1)),
            fill = "red") +
  scale_alpha_manual(values = c(0,.5)) +
  theme(legend.position = "none")
```

## Curse of dimensionality: Unpopulated cells

The curse of dimensionality is that the number of subgroups grows multiplicatively with the number of predictors. Nonparametric estimation (estimation by subgroup means) quickly becomes infeasible as the number of subgroups explodes.

```{r, echo = F}
many_groups <- d |>
  group_by(a, sex, race, mom_educ, dad_educ) |>
  summarize(n = n(),
            .groups = "drop") |>
  pivot_wider(names_from = a,
              values_from = n,
              names_prefix = "n_")
empirical_positivity_violated <- many_groups |>
  summarize(violated = weighted.mean(is.na(n_college) | is.na(n_no_college),
                                     w = ifelse(is.na(n_college),0,n_college) +
                                       ifelse(is.na(n_no_college),0,n_no_college))) |>
  mutate(violated = paste0(round(100*violated,1),"%"))
```

In fact, in our example, **`r empirical_positivity_violated$violated`** of the sample is in a subgroup where there are either zero people with college degrees or zero people without college degrees.

To make conditional exchangeability plausible, social scientists often have to draw a DAG with numerous confounding variables.

```{tikz, echo = F}
\begin{tikzpicture}[x = 1in, y = .4in]
\node (a) at (0,0) {$A$};
\node (y) at (1,0) {$Y$};
\node (l1) at (-1,2) {$L_1$};
\node (l2) at (-1,1.66) {$L_2$};
\node (l3) at (-1,1.33) {$L_3$};
\node (l4) at (-1,1) {$L_4$};
\node (l5) at (-1,.66) {$L_5$};
\node (l6) at (-1,.33) {$L_6$};
\node (l7) at (-1,0) {$L_7$};
\draw[->, thick] (l1) -- (a);
\draw[->, thick] (l2) -- (a);
\draw[->, thick] (l3) -- (a);
\draw[->, thick] (l4) -- (a);
\draw[->, thick] (l5) -- (a);
\draw[->, thick] (l6) -- (a);
\draw[->, thick] (l7) -- (a);
\draw[->, thick] (a) -- (y);
\draw[->, thick] (l1) to[bend left] (y);
\draw[->, thick] (l2) to[bend left] (y);
\draw[->, thick] (l3) to[bend left] (y);
\draw[->, thick] (l4) to[bend left] (y);
\draw[->, thick] (l5) to[bend left] (y);
\draw[->, thick] (l6) to[bend left] (y);
\draw[->, thick] (l7) to[bend left] (y);
\node[anchor = north, align = center, font = \footnotesize] at (a.south) {College\\Degree\\by Age 25};
\node[anchor = north, align = center, font = \footnotesize] at (y.south) {Spouse\\at Age 35\\Has Degree};
\node[anchor = east, align = center, font = \footnotesize] at (l1.west) {Sex};
\node[anchor = east, align = center, font = \footnotesize] at (l2.west) {Race};
\node[anchor = east, align = center, font = \footnotesize] at (l3.west) {Mom Education};
\node[anchor = east, align = center, font = \footnotesize] at (l4.west) {Dad Education};
\node[anchor = east, align = center, font = \footnotesize] at (l5.west) {Income};
\node[anchor = east, align = center, font = \footnotesize] at (l6.west) {Wealth};
\node[anchor = east, align = center, font = \footnotesize] at (l7.west) {Test Percentile};
\end{tikzpicture}
```

```{r, echo = F}
violated <- d |>
  group_by(a, sex, race, mom_educ, dad_educ, log_parent_income, log_parent_wealth, test_percentile) |>
  summarize(n = n(),
            .groups = "drop") |>
  pivot_wider(names_from = a,
              values_from = n,
              names_prefix = "n_") |>
  summarize(violated = weighted.mean(is.na(n_college) | is.na(n_no_college),
                                     w = ifelse(is.na(n_college),0,n_college) +
                                       ifelse(is.na(n_no_college),0,n_no_college))) |>
  mutate(violated = paste0(round(100*violated,1),"%"))
```

But when we add tons of variables, we have an ever-increasing problem of empty cells. With the above DAG, **`r violated$violated`** of the sample falls in a cell where either everyone is treated or everyone is untreated.

## Models to the rescue

In many real research settings, the curse of dimensionality makes it impossible to estimate nonparametrically by subgroup means. With more than a few confounders, there are simply too many subgroups and not enough sampled cases to populate them.

A **model** is the solution to this problem. A model is a statistical approach to pool information across units who fall in different subgroups, thereby allowing us to make inference even in subgroups where no units are observed. The next page introduces models through a simple descriptive example, and then we will return to causal examples to see how models can help us to answer causal questions.

If you would like to read more, you might see [Hern√°n \& Robins Ch 11](https://miguelhernan.org/whatifbook).
     