---
title: "Models for causal inference"
---

<!-- To do: Why model? page comes before this -->

Models are useful when we need subgroup summaries but we do not observe very many units in each subgroup. This situation is common in causal inference: we need to estimate the mean outcome within subgroups defined by the treatment $A$ and the confounders $\vec{X}$. Especially in observational data settings (anything that is not a randomized experiment), causal identification is most plausible when $\vec{X}$ includes many measured variables, many of which may take many values. For this reason, causal inference questions often require us to estimate the means in many subgroups that are sparsely populated.

This page introduces models for causal inference in two general approaches: outcome models and treatment models. We illustrate with a simple simulated dataset.

## Simulated data

The code below will generate a dataset of $n = 100$ observations. Each observation contains several observed variables:

* `L1` A numeric confounder
* `L2` A numeric confounder
* `A` A binary treatment
* `Y` A numeric outcome

Each observation also contains outcomes that we know only because the data are simulated. These variables are useful as ground truth in simulations.

* `propensity_score` The true propensity score $P(A = 1 \mid \vec{L})$
* `Y0` The potential outcome under control
* `Y1` The potential outcome under treatment

To run this code, you will need the `dplyr` package. If you don't have it, first run the line `install.packages("dplyr")` in your R console. Then, add this line to your R script to load the package.

```{r, message = F, warning = F}
library(dplyr)
```

If you want your simulation to match our numbers exactly, add a line to set your seed.

```{r}
set.seed(90095)
```

```{r}
n <- 500
data <- tibble(
  L1 = rnorm(n),
  L2 = rnorm(n)
) |>
  # Generate potential outcomes as functions of L
  mutate(Y0 = rnorm(n(), mean = L1 + L2, sd = 1),
         Y1 = rnorm(n(), mean = Y0 + 1, sd = 1)) |>
  # Generate treatment as a function of L
  mutate(propensity_score = plogis(-2 + L1 + L2)) |>
  mutate(A = rbinom(n(), 1, propensity_score)) |>
  # Generate factual outcome
  mutate(Y = case_when(A == 0 ~ Y0,
                       A == 1 ~ Y1))
```

A simulation is nice because the answer is known. In this simulation, the conditional average causal effect of `A` on `Y` equals 1 at any value of `L1` and `L_2`.

## Outcome modeling

Because the causal effect of `A` on `Y` is identified by adjusting for the confounders `L1` and `L2`, we can estimate by outcome modeling.

1) Model $E(Y\mid A, L_1, L_2)$, the conditional mean of $Y$ given the treatment and confounders
2) Predict potential outcomes
     * set `A = 1` for every unit. Predict $Y^1$
     * set `A = 0` for every unit. Predict $Y^0$
3) Aggregate to the average causal effect

The code below assumes you have generated data as on the [data](data.qmd) page.

```{r, echo = F, output = F, message = F, warning = F}
library(dplyr)
set.seed(90095)
n <- 500
data <- tibble(L1 = rnorm(n),
               L2 = rnorm(n)) |>
  # Generate potential outcomes as functions of L
  mutate(Y0 = rnorm(n(), mean = L1 + L2, sd = 1),
         Y1 = rnorm(n(), mean = Y0 + 1, sd = 1)) |>
  # Generate treatment as a function of L
  mutate(propensity_score = plogis(-2 + L1 + L2)) |>
  mutate(A = rbinom(n(), 1, propensity_score)) |>
  # Generate factual outcome
  mutate(Y = case_when(A == 0 ~ Y0,
                       A == 1 ~ Y1))
```

### 1) Model

The code below uses Ordinary Least Squares to estimate an outcome model.

```{r}
model <- lm(Y ~ A*(L1 + L2), data = data)
```
```{r, echo = F}
summary(model)
```

We chose a model where treatment `A` is interacted with an additive function of confounders `L1 + L2`. This is also known as a t-learner ([Kunzel et al. 2019](https://www.pnas.org/doi/abs/10.1073/pnas.1804597116)) because it is equivalent to estimating **t**wo separate regression models of outcome on confounders, one among those for whom `A == 1` and among those for whom `A == 0`.

### 2) Predict

The code below predicts the conditional average potential outcome under treatment and control at the confounder values of each observation.

First, we create data with `A` set to the value `1`.

```{r}
data_1 <- data |>
  mutate(A = 1)
```
```{r, echo = F}
data_1 |> print(n = 3)
```

Then, we create data with `A` set to the value `0`.

```{r}
data_0 <- data |>
  mutate(A = 0)
```
```{r, echo = F}
data_0 |> print(n = 3)
```

We use our outcome model to predict the conditional mean of the potential outcome under each scenario.

```{r}
predicted <- data |>
  mutate(
    Y1_predicted = predict(model, newdata = data_1),
    Y0_predicted = predict(model, newdata = data_0),
    effect_predicted = Y1_predicted - Y0_predicted
  )
```
```{r, echo = F}
predicted |> print(n = 3)
```

### 3) Aggregate

The final step is to aggregate to an average causal effect estimate.

```{r}
aggregated <- predicted |>
  summarize(average_effect_estimate = mean(effect_predicted))
```
```{r, echo = F}
aggregated |> print()
```

## Treatment modeling

Because the causal effect of `A` on `Y` is identified by adjusting for the confounders `L1` and `L2`, we can also estimate by inverse probability of treatment weighting. The intuition of this approach is that treated units (with `A == TRUE`) are a random sample of all units, within subgroups defined by `L1` and `L2`. We can infer the population-average outcome under treatment by the weighted mean outcome under treatment, with weights equal to the inverse probability of being treated.

Treatment modeling proceeds in three steps:

1) Model $P(A = 1\mid L_1, L_2)$, the conditional probability of treatment given confounders
2) Predict the conditional probability $\pi$ of each unit's observed treatment
     * if `A = 1`, predict $\pi = P(A = 1 \mid L_1,L_2)$
     * if `A = 0`, predict $\pi = P(A = 0 \mid L_1,L_2)$
3) Aggregate to the average causal effect
     * estimate the expected outcome under treatment $E(Y^1)$ by a weighted mean of treated units' outcomes, weighted by $\frac{1}{\pi}$
     * estimate the expected outcome under control $E(Y^0)$ by a weighted mean of untreated units' outcomes, weighted by $\frac{1}{\pi}$
     * estimate the average causal effect by the difference

The code below assumes you have generated data as on the [data](data.qmd) page.

```{r, echo = F, output = F, message = F, warning = F}
library(dplyr)
set.seed(90095)
n <- 500
data <- tibble(L1 = rnorm(n),
               L2 = rnorm(n)) |>
  # Generate potential outcomes as functions of L
  mutate(Y0 = rnorm(n(), mean = L1 + L2, sd = 1),
         Y1 = rnorm(n(), mean = Y0 + 1, sd = 1)) |>
  # Generate treatment as a function of L
  mutate(propensity_score = plogis(-2 + L1 + L2)) |>
  mutate(A = rbinom(n(), 1, propensity_score)) |>
  # Generate factual outcome
  mutate(Y = case_when(A == 0 ~ Y0,
                       A == 1 ~ Y1))
```

### 1) Model

The code below uses logistic regression to model the conditional probability of treatment.

```{r}
model <- glm(
  A ~ L1 + L2, 
  data = data, 
  family = binomial
)
```
```{r, echo = F}
summary(model)
```

### 2) Predict

The code below predicts the conditional probability of each unit's observed treatment value, also known as the propensity score.

```{r}
predicted <- data |>
  # Predict the probabilities that A = 1 and A = 0
  mutate(
    p_A_equals_1 = predict(model, type = "response"),
    p_A_equals_0 = 1 - p_A_equals_1
  ) |>
  # Assign the propensity score based on the observed treatment
  mutate(
    pi = case_when(
      A == 1 ~ p_A_equals_1,
      A == 0 ~ p_A_equals_0
    )
  )
```
```{r, echo = F}
predicted |> print(n = 3)
```

### 3) Aggregate

The final step is to aggregate to an average causal effect estimate.

```{r}
aggregated_Y1 <- predicted |>
  # Restrict to cases with A == 1
  filter(A == 1) |>
  # Calculate the weighted mean outcome
  summarize(estimate = weighted.mean(Y, w = 1 / pi))

aggregated_Y0 <- predicted |>
  # Restrict to cases with A == 1
  filter(A == 0) |>
  # Calculate the weighted mean outcome
  summarize(estimate = weighted.mean(Y, w = 1 / pi))

average_effect_estimate <- aggregated_Y1 - aggregated_Y0
```
```{r, echo = F}
average_effect_estimate
```

## Concluding thoughts

Outcome modeling is a powerful strategy because it bridges nonparametric causal identification to longstanding strategies where outcomes are modeled by parametric regression.

Inverse probability of treatment weighting is a powerful strategy because it bridges nonparametric causal identification to longstanding strategies from survey sampling where units from a population are sampled with known probabilities of inclusion. The analogy is that outcomes under treatment are sampled with estimated inclusion probabilities (the probability of treatment). Just as in a population sample we would need to think carefully about the probability of sampling, treatment modeling encourages us to model the probability of receiving the observed treatment.

