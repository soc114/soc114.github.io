{
  "hash": "113d154d20e1671ac2cee48cbd1e4253",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Models for causal inference\"\n---\n\n\n\n\n<!-- To do: Why model? page comes before this -->\n\nModels are useful when we need subgroup summaries but we do not observe very many units in each subgroup. This situation is common in causal inference: we need to estimate the mean outcome within subgroups defined by the treatment $A$ and the confounders $\\vec{X}$. Especially in observational data settings (anything that is not a randomized experiment), causal identification is most plausible when $\\vec{X}$ includes many measured variables, many of which may take many values. For this reason, causal inference questions often require us to estimate the means in many subgroups that are sparsely populated.\n\nThis page introduces models for causal inference in two general approaches: outcome models and treatment models. We illustrate with a simple simulated dataset.\n\n## Simulated data\n\nThe code below will generate a dataset of $n = 100$ observations. Each observation contains several observed variables:\n\n* `L1` A numeric confounder\n* `L2` A numeric confounder\n* `A` A binary treatment\n* `Y` A numeric outcome\n\nEach observation also contains outcomes that we know only because the data are simulated. These variables are useful as ground truth in simulations.\n\n* `propensity_score` The true propensity score $P(A = 1 \\mid \\vec{L})$\n* `Y0` The potential outcome under control\n* `Y1` The potential outcome under treatment\n\nTo run this code, you will need the `dplyr` package. If you don't have it, first run the line `install.packages(\"dplyr\")` in your R console. Then, add this line to your R script to load the package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n:::\n\n\n\n\nIf you want your simulation to match our numbers exactly, add a line to set your seed.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(90095)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 500\ndata <- tibble(\n  L1 = rnorm(n),\n  L2 = rnorm(n)\n) |>\n  # Generate potential outcomes as functions of L\n  mutate(Y0 = rnorm(n(), mean = L1 + L2, sd = 1),\n         Y1 = rnorm(n(), mean = Y0 + 1, sd = 1)) |>\n  # Generate treatment as a function of L\n  mutate(propensity_score = plogis(-2 + L1 + L2)) |>\n  mutate(A = rbinom(n(), 1, propensity_score)) |>\n  # Generate factual outcome\n  mutate(Y = case_when(A == 0 ~ Y0,\n                       A == 1 ~ Y1))\n```\n:::\n\n\n\n\nA simulation is nice because the answer is known. In this simulation, the conditional average causal effect of `A` on `Y` equals 1 at any value of `L1` and `L_2`.\n\n## Outcome modeling\n\nBecause the causal effect of `A` on `Y` is identified by adjusting for the confounders `L1` and `L2`, we can estimate by outcome modeling.\n\n1) Model $E(Y\\mid A, L_1, L_2)$, the conditional mean of $Y$ given the treatment and confounders\n2) Predict potential outcomes\n     * set `A = 1` for every unit. Predict $Y^1$\n     * set `A = 0` for every unit. Predict $Y^0$\n3) Aggregate to the average causal effect\n\nThe code below assumes you have generated data as on the [data](data.qmd) page.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n### 1) Model\n\nThe code below uses Ordinary Least Squares to estimate an outcome model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(Y ~ A*(L1 + L2), data = data)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Y ~ A * (L1 + L2), data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1448 -0.7105  0.0097  0.6998  3.1743 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.01606    0.05699   0.282  0.77827    \nA            1.11555    0.18021   6.190 1.26e-09 ***\nL1           1.06333    0.05938  17.907  < 2e-16 ***\nL2           1.11199    0.05951  18.685  < 2e-16 ***\nA:L1        -0.39475    0.14279  -2.765  0.00591 ** \nA:L2        -0.28935    0.13940  -2.076  0.03844 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.111 on 494 degrees of freedom\nMultiple R-squared:  0.6732,\tAdjusted R-squared:  0.6699 \nF-statistic: 203.6 on 5 and 494 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\nWe chose a model where treatment `A` is interacted with an additive function of confounders `L1 + L2`. This is also known as a t-learner ([Kunzel et al. 2019](https://www.pnas.org/doi/abs/10.1073/pnas.1804597116)) because it is equivalent to estimating **t**wo separate regression models of outcome on confounders, one among those for whom `A == 1` and among those for whom `A == 0`.\n\n### 2) Predict\n\nThe code below predicts the conditional average potential outcome under treatment and control at the confounder values of each observation.\n\nFirst, we create data with `A` set to the value `1`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_1 <- data |>\n  mutate(A = 1)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 × 7\n        L1     L2      Y0    Y1 propensity_score     A       Y\n     <dbl>  <dbl>   <dbl> <dbl>            <dbl> <dbl>   <dbl>\n1  0.00304  1.03   0.677   1.59          0.276       1  0.677 \n2 -2.35    -1.66  -4.09   -3.53          0.00244     1 -4.09  \n3  0.104   -0.912  0.0659  1.31          0.0569      1  0.0659\n# ℹ 497 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThen, we create data with `A` set to the value `0`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_0 <- data |>\n  mutate(A = 0)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 × 7\n        L1     L2      Y0    Y1 propensity_score     A       Y\n     <dbl>  <dbl>   <dbl> <dbl>            <dbl> <dbl>   <dbl>\n1  0.00304  1.03   0.677   1.59          0.276       0  0.677 \n2 -2.35    -1.66  -4.09   -3.53          0.00244     0 -4.09  \n3  0.104   -0.912  0.0659  1.31          0.0569      0  0.0659\n# ℹ 497 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWe use our outcome model to predict the conditional mean of the potential outcome under each scenario.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredicted <- data |>\n  mutate(\n    Y1_predicted = predict(model, newdata = data_1),\n    Y0_predicted = predict(model, newdata = data_0),\n    effect_predicted = Y1_predicted - Y0_predicted\n  )\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 × 10\n        L1     L2      Y0    Y1 propensity_score     A       Y Y1_predicted\n     <dbl>  <dbl>   <dbl> <dbl>            <dbl> <int>   <dbl>        <dbl>\n1  0.00304  1.03   0.677   1.59          0.276       0  0.677         1.98 \n2 -2.35    -1.66  -4.09   -3.53          0.00244     0 -4.09         -1.81 \n3  0.104   -0.912  0.0659  1.31          0.0569      0  0.0659        0.451\n# ℹ 497 more rows\n# ℹ 2 more variables: Y0_predicted <dbl>, effect_predicted <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n### 3) Aggregate\n\nThe final step is to aggregate to an average causal effect estimate.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregated <- predicted |>\n  summarize(average_effect_estimate = mean(effect_predicted))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  average_effect_estimate\n                    <dbl>\n1                    1.13\n```\n\n\n:::\n:::\n\n\n\n\n## Treatment modeling\n\nBecause the causal effect of `A` on `Y` is identified by adjusting for the confounders `L1` and `L2`, we can also estimate by inverse probability of treatment weighting. The intuition of this approach is that treated units (with `A == TRUE`) are a random sample of all units, within subgroups defined by `L1` and `L2`. We can infer the population-average outcome under treatment by the weighted mean outcome under treatment, with weights equal to the inverse probability of being treated.\n\nTreatment modeling proceeds in three steps:\n\n1) Model $P(A = 1\\mid L_1, L_2)$, the conditional probability of treatment given confounders\n2) Predict the conditional probability $\\pi$ of each unit's observed treatment\n     * if `A = 1`, predict $\\pi = P(A = 1 \\mid L_1,L_2)$\n     * if `A = 0`, predict $\\pi = P(A = 0 \\mid L_1,L_2)$\n3) Aggregate to the average causal effect\n     * estimate the expected outcome under treatment $E(Y^1)$ by a weighted mean of treated units' outcomes, weighted by $\\frac{1}{\\pi}$\n     * estimate the expected outcome under control $E(Y^0)$ by a weighted mean of untreated units' outcomes, weighted by $\\frac{1}{\\pi}$\n     * estimate the average causal effect by the difference\n\nThe code below assumes you have generated data as on the [data](data.qmd) page.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n### 1) Model\n\nThe code below uses logistic regression to model the conditional probability of treatment.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- glm(\n  A ~ L1 + L2, \n  data = data, \n  family = binomial\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = A ~ L1 + L2, family = binomial, data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -2.0740     0.1737 -11.938  < 2e-16 ***\nL1            1.0845     0.1639   6.618 3.65e-11 ***\nL2            1.1877     0.1548   7.673 1.68e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 474.41  on 499  degrees of freedom\nResidual deviance: 354.86  on 497  degrees of freedom\nAIC: 360.86\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n\n\n### 2) Predict\n\nThe code below predicts the conditional probability of each unit's observed treatment value, also known as the propensity score.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredicted <- data |>\n  # Predict the probabilities that A = 1 and A = 0\n  mutate(\n    p_A_equals_1 = predict(model, type = \"response\"),\n    p_A_equals_0 = 1 - p_A_equals_1\n  ) |>\n  # Assign the propensity score based on the observed treatment\n  mutate(\n    pi = case_when(\n      A == 1 ~ p_A_equals_1,\n      A == 0 ~ p_A_equals_0\n    )\n  )\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 × 10\n        L1     L2      Y0    Y1 propensity_score     A       Y p_A_equals_1\n     <dbl>  <dbl>   <dbl> <dbl>            <dbl> <int>   <dbl>        <dbl>\n1  0.00304  1.03   0.677   1.59          0.276       0  0.677       0.300  \n2 -2.35    -1.66  -4.09   -3.53          0.00244     0 -4.09        0.00136\n3  0.104   -0.912  0.0659  1.31          0.0569      0  0.0659      0.0455 \n# ℹ 497 more rows\n# ℹ 2 more variables: p_A_equals_0 <dbl>, pi <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n### 3) Aggregate\n\nThe final step is to aggregate to an average causal effect estimate.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregated_Y1 <- predicted |>\n  # Restrict to cases with A == 1\n  filter(A == 1) |>\n  # Calculate the weighted mean outcome\n  summarize(estimate = weighted.mean(Y, w = 1 / pi))\n\naggregated_Y0 <- predicted |>\n  # Restrict to cases with A == 1\n  filter(A == 0) |>\n  # Calculate the weighted mean outcome\n  summarize(estimate = weighted.mean(Y, w = 1 / pi))\n\naverage_effect_estimate <- aggregated_Y1 - aggregated_Y0\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  estimate\n1 1.288555\n```\n\n\n:::\n:::\n\n\n\n\n## Concluding thoughts\n\nOutcome modeling is a powerful strategy because it bridges nonparametric causal identification to longstanding strategies where outcomes are modeled by parametric regression.\n\nInverse probability of treatment weighting is a powerful strategy because it bridges nonparametric causal identification to longstanding strategies from survey sampling where units from a population are sampled with known probabilities of inclusion. The analogy is that outcomes under treatment are sampled with estimated inclusion probabilities (the probability of treatment). Just as in a population sample we would need to think carefully about the probability of sampling, treatment modeling encourages us to model the probability of receiving the observed treatment.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}